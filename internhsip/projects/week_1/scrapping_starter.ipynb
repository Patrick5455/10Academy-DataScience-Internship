{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scrapping using python\n",
    "\n",
    "#### References\n",
    "1. [Practical Introduction to Web Scraping in Python](https://realpython.com/python-web-scraping-practical-introduction/)\n",
    "2. [Web Scraping using Python](https://www.datacamp.com/community/tutorials/web-scraping-using-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import re\n",
    "# import fire\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile ../pyscrap_url.py\n",
    "\n",
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at `url` by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                return resp.content  #.encode(BeautifulSoup.original_encoding)\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Returns True if the response seems to be HTML, False otherwise.\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "\n",
    "def log_error(e):\n",
    "    \"\"\"\n",
    "    It is always a good idea to log errors. \n",
    "    This function just prints them, but you can\n",
    "    make it do anything.\n",
    "    \"\"\"\n",
    "    print(e)\n",
    "    \n",
    "def get_elements(url, tag='',search={}, fname=None):\n",
    "    \"\"\"\n",
    "    Downloads a page specified by the url parameter\n",
    "    and returns a list of strings, one per tag element\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(url,str):\n",
    "        response = simple_get(url)\n",
    "    else:\n",
    "        #if already it is a loaded html page\n",
    "        response = url\n",
    "\n",
    "    if response is not None:\n",
    "        html = BeautifulSoup(response, 'html.parser')\n",
    "        \n",
    "        res = []\n",
    "        if tag:    \n",
    "            for li in html.select(tag):\n",
    "                for name in li.text.split('\\n'):\n",
    "                    if len(name) > 0:\n",
    "                        res.append(name.strip())\n",
    "                       \n",
    "                \n",
    "        if search:\n",
    "            soup = html            \n",
    "            \n",
    "            \n",
    "            r = ''\n",
    "            if 'find' in search.keys():\n",
    "                print('finding',search['find'])\n",
    "                soup = soup.find(**search['find'])\n",
    "                r = soup\n",
    "\n",
    "                \n",
    "            if 'find_all' in search.keys():\n",
    "                print('findaing all of',search['find_all'])\n",
    "                r = soup.find_all(**search['find_all'])\n",
    "   \n",
    "            if r:\n",
    "                for x in list(r):\n",
    "                    if len(x) > 0:\n",
    "                        res.extend(x)\n",
    "            \n",
    "        return res\n",
    "\n",
    "    # Raise an exception if we failed to get any data from the url\n",
    "    raise Exception('Error retrieving contents at {}'.format(url))    \n",
    "    \n",
    "    \n",
    "if get_ipython().__class__.__name__ == '__main__':\n",
    "    fire(get_tag_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Scrape data from [africafreak.com](https://africafreak.com/100-most-influential-twitter-users-in-africa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_elements('https://africafreak.com/100-most-influential-twitter-users-in-africa', tag='h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_govt_influencers = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_govt_influencers = pd.Series(non_govt_influencers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "afriq_users_handle = [i.split('(')[-1].strip(')') for i in non_govt_influencers]\n",
    "afriq_users_handle=afriq_users_handle[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> correct incorrect tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "afriq_users_handle[12] = '@beyondsafari'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> pars to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afriq_users_handle = pd.DataFrame(afriq_users_handle, columns=['handles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@gettleman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@a24media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@andiMakinana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@AfricaCheck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@JamesCopnall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>@Julius_S_Malema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>@News24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>@SAPresident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>@GarethCliff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>@Trevornoah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             handles\n",
       "0         @gettleman\n",
       "1          @a24media\n",
       "2      @andiMakinana\n",
       "3       @AfricaCheck\n",
       "4      @JamesCopnall\n",
       "..               ...\n",
       "95  @Julius_S_Malema\n",
       "96           @News24\n",
       "97      @SAPresident\n",
       "98      @GarethCliff\n",
       "99       @Trevornoah\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_afriq_users_handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afriq_users_handle.to_csv('scraped_handles/top_100_influencers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Scrape data from [atlanticcouncil.org](https://www.atlanticcouncil.org/blogs/africasource/african-leaders-respond-to-coronavirus-on-twitter/#east-africa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Deputy Prime Minister Themba Masuku has today met representatives of the private sector and employees' unions to map a collaborative effort in the fight against #COVID19. pic.twitter.com/EIYNGOEKRN— Eswatini Government (@EswatiniGovern1) March 20, 2020\",\n",
       " 'GUIDELINES FOR SCHOOLS IN #MALAWI ON THE PREVENTION AND MANAGEMENT OF #COVID19 #CORONAVIRUS pic.twitter.com/PL9R4XvGV3— Malawi Government (@MalawiGovt) March 18, 2020']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url= 'https://www.atlanticcouncil.org/blogs/africasource/african-leaders-respond-to-coronavirus-on-twitter/#east-africa'\n",
    "response = get(url).content\n",
    "res = get_elements(response, tag='blockquote')\n",
    "res[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "afriq_govt = []\n",
    "afriq_govt_handle = []\n",
    "for r in res:\n",
    "    split_data = r.split('— ',maxsplit=1)[1].rsplit('(',maxsplit=1)\n",
    "    name = split_data[0].split(',')[0].strip()\n",
    "    handle =  split_data[1].rsplit(')',maxsplit=1)[0]\n",
    "    user = str(name), str(handle)\n",
    "    afriq_govt.append(user)\n",
    "    afriq_govt_handle.append(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "findaing all of {'class_': 'wp-block-embed__wrapper'}\n"
     ]
    }
   ],
   "source": [
    "res_ = simple_get(url)\n",
    "res = get_elements(res_, search={'find_all':{'class_':'wp-block-embed__wrapper'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= pd.DataFrame({'names':res})\n",
    "x['names'] = x[x['names'].apply(lambda x: \"twitter.com\" in x)]\n",
    "x.dropna(inplace=True)\n",
    "links = x.names.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in links:\n",
    "    name = link.split('/')[3]\n",
    "    handle = '@'+name\n",
    "    user= str(name), str(handle)\n",
    "    afriq_govt.append(user)\n",
    "    afriq_govt_handle.append(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@EswatiniGovern1']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afriq_govt_handle[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "afriq_govt_handle = pd.DataFrame(afriq_govt_handle, columns=['handles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "afriq_govt_handle.to_csv('scraped_handles/africa_govt_covid_resp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data From Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Importing libraies & preparing api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import API\n",
    "from tweepy import Cursor\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from collections import Counter\n",
    "import sys\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_key API_secret_key Access_token Access_token_secret\n"
     ]
    }
   ],
   "source": [
    "API_key=\"API_key\"\n",
    "API_secret_key=\"API_secret_key\"\n",
    "Access_token=\"Access_token\"\n",
    "Access_token_secret=\"Access_token_secret\"\n",
    "print(API_key, API_secret_key, Access_token, Access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = os.environ.get(API_key)\n",
    "API_secret_key = os.environ.get(API_secret_key)\n",
    "Access_token = os.environ.get(Access_token)\n",
    "Access_token_secret=os.environ.get(Access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(API_key, API_secret_key)\n",
    "auth.set_access_token(Access_token, Access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "auth_api = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Testing Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = \"#wildfires\"\n",
    "date_since= \"2018-11-16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @m_parrington: Mid-July view of #Siberia/#ArcticCircle #wildfires with #CopernicusAtmosphere Monitoring Service GFAS #opendata. Arctic d…\n",
      "#napa #santarosa #grimesfire #ventura #fresnocounty #riversidecounty #veyowestfire #sonomacounty #benfire… https://t.co/TkKznU3P5l\n"
     ]
    }
   ],
   "source": [
    "# Collect tweets\n",
    "tweets = tweepy.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"en\",\n",
    "              since=date_since).items(2)\n",
    "# Iterate and print tweets\n",
    "for tweet in tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> influential African Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(handles):\n",
    "    \n",
    "    cols = ['id', 'name', 'screen_name', 'description', \n",
    "            'statuses_count', 'friends_count', 'followers_count', \n",
    "            'account_age_days', 'avg_daily_tweets', 'hashtags',\n",
    "            'user_mentions','favorite_count', 'retweet_count',]\n",
    "    \n",
    "    # dataframe that would be returned at the end\n",
    "    #df = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    value_list = []\n",
    "    handle_data = []\n",
    "    off_users = []\n",
    "            \n",
    "    if len(handles) > 0:    \n",
    "        for handle in handles:\n",
    "            print(\"Getting data for \" + handle)\n",
    "            try:\n",
    "                item = auth_api.get_user(handle)\n",
    "            except tweepy.TweepError as e:\n",
    "                continue\n",
    "            value_list+= item.id_str, item.name, item.screen_name,\\\n",
    "            item.description, item.statuses_count, item.friends_count, item.followers_count\n",
    "            \n",
    "            #get average daily tweets\n",
    "            \n",
    "            no_tweets = item.statuses_count\n",
    "            account_created_date = item.created_at\n",
    "            delta = datetime.utcnow() - account_created_date\n",
    "            account_age_days = delta.days\n",
    "            value_list.append(str(account_age_days))\n",
    "            #print(str(account_age_days))\n",
    "            if account_age_days > 0:\n",
    "                   value_list.append(int(float(no_tweets)/float(account_age_days)))\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            hashtags = []\n",
    "            mentions = []\n",
    "            favorite_count =[]\n",
    "            retweet_count=[]\n",
    "            tweet_count = 0\n",
    "            end_date = datetime.utcnow() - timedelta(days=30)\n",
    "            \n",
    "#             try:\n",
    "#                 items =  \n",
    "#             except:\n",
    "                \n",
    "\n",
    "            for status in Cursor(auth_api.user_timeline, id=handle).items():\n",
    "                tweet_count+= 1\n",
    "                if hasattr(status, \"entities\"):\n",
    "                    entities = status.entities\n",
    "\n",
    "                # get hashtags\n",
    "                if \"hashtags\" in entities:\n",
    "                    for ent in entities[\"hashtags\"]:\n",
    "                        if ent is not None:\n",
    "                            if \"text\" in ent:\n",
    "                                hashtag = ent[\"text\"]\n",
    "                                if hashtag is not None:\n",
    "                                    hashtags.append(hashtag)\n",
    "                # get usermentions\n",
    "                if \"user_mentions\" in entities:\n",
    "                    for ent in entities[\"user_mentions\"]:\n",
    "                        if ent is not None:\n",
    "                            if \"screen_name\" in ent:\n",
    "                                name = ent[\"screen_name\"]\n",
    "                                if name is not None:\n",
    "                                    mentions.append(name)\n",
    "\n",
    "                # get retweets    \n",
    "                if hasattr(status, \"retweet_count\"):\n",
    "                    retweets = status.retweet_count\n",
    "                    if retweets is not None:\n",
    "                        retweet_count.append(retweets)\n",
    "                        \n",
    "                # favorite count     \n",
    "                if hasattr(status, \"favorite_count\"):\n",
    "                    likes = status.favorite_count \n",
    "                    if likes is not None:\n",
    "                        favorite_count.append(likes)\n",
    "                if status.created_at < end_date:\n",
    "                    break\n",
    "                    \n",
    "            \n",
    "            value_list.append(len(hashtags))\n",
    "            value_list.append(len(mentions))\n",
    "            value_list.append(sum(favorite_count))\n",
    "            value_list.append(sum(retweet_count))\n",
    "            #handle_data.extend(value_list)\n",
    "            #print(value_list)\n",
    "            #break\n",
    "    df= pd.DataFrame([value_list], columns=cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# if len(account_list) > 0:\n",
    "#   for target in account_list:\n",
    "#     print(\"Getting data for \" + target)\n",
    "#     item = auth_api.get_user(target)\n",
    "#     print(\"name: \" + item.name)\n",
    "#     print(\"screen_name: \" + item.screen_name)\n",
    "#     print(\"description: \" + item.description)\n",
    "#     print(\"statuses_count: \" + str(item.statuses_count))\n",
    "#     print(\"friends_count: \" + str(item.friends_count))\n",
    "#     print(\"followers_count: \" + str(item.followers_count))\n",
    "    \n",
    "    \n",
    "# tweets = item.statuses_count\n",
    "# account_created_date = item.created_at\n",
    "# delta = datetime.utcnow() - account_created_date\n",
    "# account_age_days = delta.days\n",
    "# print(\"Account age (in days): \" + str(account_age_days))\n",
    "# if account_age_days > 0:\n",
    "# print(\"Average tweets per day: \" + \"%.2f\"%(float(tweets)/float(account_age_days)))\n",
    "    \n",
    "# hashtags = []\n",
    "# mentions = []\n",
    "# favorite_count =[]\n",
    "# retweet_count=[]\n",
    "# tweet_count = 0\n",
    "# end_date = datetime.utcnow() - timedelta(days=30)\n",
    "\n",
    "#     for status in Cursor(auth_api.user_timeline, id=target).items():\n",
    "#         tweet_count += 1\n",
    "#         if hasattr(status, \"entities\"):\n",
    "#         entities = status.entities\n",
    "        \n",
    "#         # get hashtags\n",
    "#         if \"hashtags\" in entities:\n",
    "#             for ent in entities[\"hashtags\"]:\n",
    "#             if ent is not None:\n",
    "#                 if \"text\" in ent:\n",
    "#                     hashtag = ent[\"text\"]\n",
    "#                 if hashtag is not None:\n",
    "#                     hashtags.append(hashtag)\n",
    "#         value_list+=len(hashtags)\n",
    "#         # get usermentions\n",
    "#         if \"user_mentions\" in entities:\n",
    "#             for ent in entities[\"user_mentions\"]:\n",
    "#                 if ent is not None:\n",
    "#                     if \"screen_name\" in ent:\n",
    "#                         name = ent[\"screen_name\"]\n",
    "#                         if name is not None:\n",
    "#                             mentions.append(name)\n",
    "#         value_list+=len(mentions)\n",
    "                                              \n",
    "#         # get retweets    \n",
    "#         if hasattr(status, \"retweet_count\"):\n",
    "#             retweets = status.retweet_count\n",
    "#             if retweets is not None:\n",
    "#                 retweet_count.append(retweets)\n",
    "#         value_list+=sum(retweet_count)\n",
    "\n",
    "#         # favorite count     \n",
    "#         if hasattr(status, \"favorite_count\"):\n",
    "#             likes = status.favorite_count \n",
    "#             if likes is not None:\n",
    "#                 favorite_count.append(likes)\n",
    "#         value_list+=sum(retweet_count)\n",
    "#         if status.created_at < end_date:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@gettleman', '@a24media', '@andiMakinana', '@AfricaCheck', '@JamesCopnall']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =afriq_users_handle[:5]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for @gettleman\n",
      "Getting data for @a24media\n",
      "Getting data for @andiMakinana\n",
      "Getting data for @AfricaCheck\n",
      "Getting data for @JamesCopnall\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "13 columns passed, passed data had 65 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    496\u001b[0m         result = _convert_object_array(\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[0;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    580\u001b[0m             raise AssertionError(\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m                 \u001b[0;34mf\"{len(content)} columns\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 13 columns passed, passed data had 65 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-e8e8734d6d8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-7199a47856f6>\u001b[0m in \u001b[0;36mget_tweets\u001b[0;34m(handles)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m#print(value_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m#break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    472\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# columns if columns is not None else []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         return _list_of_dict_to_arrays(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    498\u001b[0m         )\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 13 columns passed, passed data had 65 columns"
     ]
    }
   ],
   "source": [
    "test_=get_tweets(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-363ed98a7589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_' is not defined"
     ]
    }
   ],
   "source": [
    "test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\nhttps://twitter.com/TsholetsaDomi/status/1238324860536922112\\n',\n",
       "       '\\nhttps://twitter.com/Azali_officiel/status/1239649350747332613\\n',\n",
       "       '\\nhttps://twitter.com/SE_Rajoelina/status/1241101811647500288\\n',\n",
       "       '\\nhttps://twitter.com/PKJugnauth/status/1240740484714319872\\n',\n",
       "       '\\nhttps://twitter.com/AbiyAhmedAli/status/1240291553056260099\\n',\n",
       "       '\\nhttps://twitter.com/PR_Paul_BIYA/status/1239988020763398147\\n',\n",
       "       '\\nhttps://twitter.com/MinistereComCG/status/1239695479476293632\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.names.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
